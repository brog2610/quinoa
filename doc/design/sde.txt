General requirements:
=====================

 * Numerical time integration of stochastic differential equations (SDE) is
   probably the single most important ingredient. This must be:
    - Efficient
    - Maintainable
    - The design must scale well with adding new functionality (.e., adding new
      equations and/or new models for already implemented equations should
      require as little code as possible
    - Should easily accommodate various advancement algorithms on different
      hardware end/or using various parallelization strategies

 * There should be a possibility to quickly prototype a new SDE, e.g., in a
   test-bed class. This is used to:
    - Verify its invariant PDF
    - Explore the behavior of its statistics
    - Integrate multiple variables (coupled or non-coupled)

 * Data layout:
   How should the particle properties should be stored in memory? This is the
   single largest chunk of data that a particle-based code will have. The
   layout determines how the data is accessed and potentially has a
   first-degree effect on overall efficiency.

   Possibilities:
   --------------
    (A) Particle-major, in which various physical properties, e.g., position,
        velocity, energy, etc., of a single particle are close to each other
        in memory. For example: [ x1, y1, z1, ..., x2, y2, z2, ..., x3, y3,
        z3, ... ] where the x* are governed by one SDE (e.g., position), the
        y* are governed by another SDE (e.g., velocity), and the z* are
        governed by a third SDE (e.g., energy), etc. Here the first letter
        denotes a physical quantity, while the second is the particle number.
        If the algorithm that advances the properties in time applies one SDE
        at a time, the SDEs will access data by having to jump a distance that
        corresponds to the number of scalar physical variables per particle.
        In the example, the update will have to jump as x1, x2, x3, ... are
        updated.
    (B) Property-major, in which the same type of physical properties are
        close to each other in memory. For example, [ x1, x2, x3, ..., y1, y2,
        y3, ..., z1, z2, z3, ... ]. The legend here is the same as in
        particle-major: the first letter denotes a physical quantity, while
        the second is the particle number. If the algorithm that advances the
        properties in time applies one SDE at a time, the SDEs will access
        data contiguously in memory as the properties are contiguously stored.

   Discussion:
   -----------
    - A property-major storage, case (B) above, seems to be the most efficient
      at first sight, as it stores data, as it is read and written by the SDE
      algorithms, contiguously. However, data access is contiguous only if the
      particle properties are independent, i.e., if there is no coupling among
      the SDEs. Unfortunately, this is rarely the case, at least not for fluid
      dynamics. For example, position is used by the velocity update, and
      velocity is required by the energy update. Depending on the physical
      approximation, density (or mass) may be required for all SDEs. The
      stronger the SDEs are coupled the more very-far-reads are required for a
      given update. These far-reads are potentially almost always cache misses,
      as the property-major storage stores the physical variables for the same
      particle very far in memory, e.g., the distance between x1 and y1 is the
      number of particles. While the particle-major storage, case (A) above,
      inherently stores data non-contiguously, the distance between properties
      of a single particle is relatively small, i.e., the number of properties,
      which may incure less cache misses as several particle with all of their
      properties could fit into cache.
    - Assuming strong coupling among the variables, the particle-major storage
      will be favored, but it would be nice if the design allowed for both
      layouts, so depending on the type of equations (e.g., non-fluid-dynamics)
      the most appropriate layout could be selected. If such a design is
      maintanable, there is still a question wether the data layout selection
      should be done at compile-, or run-time.
    - Have looked at https://code.google.com/p/blaze-lib, which implements row-,
      and column-major matrix classes based on a template argument. See, e.g.,
      blaze-1.5/blaze/math/dense/StaticMatrix.h, which reveals that the template
      argument (bool) SO selects between row-, or column-major internal storage.
      Then SO is used at both compile-time (e.g., by the class-user, when
      instantiating the type of the matrix), as well as run-time (e.g., the
      implementation of isDefault()). Both compile-time and run-time usage of
      the SO template arguments are problematic:
      1. The compile-time usage duplicates a lot of code by having to provide
         similar implementations for the element-access operator() of
         StaticMatrix specialized to column-major. There is a generic
         implementation for SO for everthing that is agnostic of SO, and there
         is a specialization when SO = column-major.
      2. The run-time usage also duplicates code by doing an if-test on SO in
         e.g., isDefault().
      Is there a better way of doing this? If there are only two types of data
      layout (particle-, and property-major), code duplication should not be too
      much of an issue. However, the implementation of particle-property data
      access must be absolutely zero run-time cost. This means the selection
      must be at compile-time and the element access must be absolutely
      invisible to the derived SDE classes. In other words, there must be no
      re-implementation of a time-integrator for an SDE just because the data
      access is different.

 * Questions:
    - Should SDE base hold a single RNG used by all specific (derived) SDEs or
      different SDEs should be able to instantiate and use their own (possibly
      different) RNGs?

    - What new requirements and constraints does spatial inhomogeneity entail?

Requirements on SDE base:
=========================

 * SDEs should inherit at least from one base class (if a multiple-policy
   design is adopted) that should have SDE-generic data and member functions,
   which facilitates code-reuse.

 * Base SDE class should work for both N = 1 or N > 1, i.e., single-variate or
   multi-variate SDEs.

 * Base SDE class should have pure virtual interfaces for:
    - Initialization of the particles at t = 0, e.g., init()
    - Advancing the particles in time, e.g., advance()

 * Possible policies of an SDE base class:

    - Initialization policy:
      ---------------------
      Specifies how the initialization of the particles happen at t = 0.
      Possible initialization policies:
       o Do nothing: leave memory associated to particle data uninitialized
       o Zero: zero particle properties
       o Fill with one given constant: single-delta-spike PDF
       o Fill with different constants given per variable
       o Sample from given PDF, N = 1
       o Sample from different PDF given per variable, N > 1 (independent)
       o Sample from given JPDF, N > 1 (possibly non-independent)
       o Pre-cycle properties using a given SDE and its constant coefficients
         for:
         - a given time period
         - a given number of time steps
         - until convergence is reached for given statistics and convergence
           criteria

   - Time-integration policy:
     ------------------------
     Specifies what time-integrator to use when advancing particles.
     Possible time-integration policies:
       o Euler-Maruyama
       o Milstein
       o Runge-Kutta (with various orders)
       o Various other explicit and implicit integrators, see Kloeden & Platen

   - Data-layout policy:
     -------------------
     Specifies which data layout policy is used internally to access particle
     data.
     Possible data-layout policies:
       o Particle-major
       o Property-major
     Is it possible to implement this policy via a thin data-access interface
     with zero run-time cost, no code-duplication and in a way that is invisible
     to derived SDE classes?

 * Specific SDE types (e.g., Ornstein-Uhlenbeck, Dirichlet, skew-normal, etc),
   should derive from the SDE base class, forwarding base class policies, i.e.,
   a specific SDE class should not hard-code any base class policy.

 * Specific SDE classes may have their own policies (specific to the given SDE).

 * Questions:
    - What new requirements and constraints does spatial inhomogeneity entail?

Requirements on SDE Dirichlet:
==============================

 * Should derive from SDE base

 * Dirichlet SDE possible policies:

    - Coefficients policy:
      --------------------
      Specifies how the coefficients, b, S, and kappa, are used by the SDE.
      Possible coefficients policies:
       o Constant: initialized once, used for all t > 0 (e.g., for testing)
       o Functional: advance() algorithm queries coefficients at every update
         via functions, e.g., b(time, various statistics)

 * Questions:
    - What new requirements and constraints does spatial inhomogeneity entail?
      This may only affect a functional coefficients policy that is used to
      define a spatially inhomogeneous Dirichlet SDE model.
